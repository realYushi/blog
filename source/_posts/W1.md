---
title: Dev-log, Week 1, To-Do List App
date: 2024-06-19 15:07:23
tags:
    - project
    - To-Do List
    - Dev-log
---

### Week 1: Setup and Initial Planning

-   **Setup Development Environment:** Install necessary software and tools on macOS.
-   **Version Control Initialization:** Set up Git repositories on GitHub, including branch management strategies.
-   **Docker Configuration:** Write Dockerfiles and docker-compose.yml for containerizing both frontend and backend.
-   **CI/CD Pipeline Setup:** Initialize CI/CD using GitHub Actions or Jenkins to automate the build, test, and deploy process.
-   **Behavior-Driven Development (BDD) Session:** Conduct a BDD session to define and model how the application should behave in various scenarios.
-   **Begin TDD Frameworks:** Establish TDD environments using Jest, React Testing Library for the frontend, and NUnit/xUnit for the backend. Write initial tests to guide development.

---

### Day 1: Setting Up My Development Environment

Today marked the beginning of my journey in building a full-stack To-Do list application. I started by refreshing my workspace—an essential step to ensure everything runs smoothly. Here's a detailed breakdown of how I set up my development environment on my MacBook M1:

1. **Resetting My System:** To start with a clean slate, I reset everything and began setting up my development tools from scratch.

2. **Terminal and Shell Configuration:**

    - **Oh My Zsh:** Installed to customize and manage my zsh configuration efficiently.
    - **Warp:** Chosen as my terminal due to its user-friendly Vim key bindings.

3. **Package Management and Software Installation:**
    - **Homebrew:** Installed as the software manager to handle various installations.
    - **Mise:** Utilized for managing different runtime versions for various projects.
    - **Visual Studio Code (VSCode):** Selected as my primary code editor. I installed several extensions to enhance functionality, though I’m still considering whether to switch to Rider IDE for .NET development. For now, VSCode remains my choice.
    - **Postman:** Installed for API testing, a new tool for me, recommended by many developers.
    - **PostgreSQL:** Set up as the development database. Plans are in place to switch to MSSQL for production.
    - **Docker:** Installed to manage and maintain containerized applications.
    - **Local Git Configuration:** Set up for version control, including connecting to GitHub via SSH.
    - **Browsers and Developer Tools:**
        - **Chromium:** Installed along with React and Redux development tools to experiment with these technologies.

Today’s focus was primarily on establishing a robust and flexible development environment that will support the diverse technologies involved in my project. By the end of the day, I successfully:

-   Reset my system and configured my terminal using Oh My Zsh.
-   Managed software installations with Homebrew and runtime versions with Mise.
-   Prepared my IDE with necessary extensions and tools for backend and frontend development.
-   Set up essential services like PostgreSQL, Docker, and Postman for effective development practices.

This setup lays a solid foundation for the weeks to come, ensuring that I have all the tools I need at my disposal to tackle the challenges of building a full-stack application.

---

### Day 2: Setting Up Git Repositories and Exploring Branch Management Strategies

Continuing with my development plan, today's focus shifted towards establishing a solid version control system. I took some significant steps to ensure that my project management and workflow are both efficient and effective.

**Establishing the GitHub Repository:**

I created a new repository for my To-Do List project, which can be found [here](https://github.com/realYushi/todo-list). Although the repository is currently empty, I'm confident it will soon be filled with the progress of my application. With ChatGPT's help, I crafted a well-structured README file to provide an overview of the project.

**Branch Management:**

Given that this is a solo project, I opted for a straightforward branch management strategy:

-   **Main:** Serves as the production branch.
-   **Development:** This is where all ongoing development will be merged and tested.
-   **Feature/newFeature:** Used for developing new features. Once features are stable, they will be merged into the 'Development' branch and eventually into 'Main' for production.
-   **Hotfix:** For emergency fixes, which will also follow the path of merging back to 'Main' and be deleted post-merge to maintain cleanliness in the repository.

During my research, I stumbled upon an intriguing tool called OpenCommit, which utilizes ChatGPT to analyze git diffs and generate meaningful commit messages. Intrigued by its capabilities, I decided to incorporate it into my workflow to see how AI can enhance traditional coding practices.

Additionally, I utilized gitignore.io to generate a comprehensive `.gitignore` file, ensuring that unnecessary files don’t clutter the repository.

**What I Learned Today:**

-   **Repository Setup:** I learned how to create a new repository on GitHub and link it to my local environment.
-   **Branch Management:** I gained insights into managing branches effectively for a streamlined development process.
-   **AI Integration:** Experimented with AI tools like OpenCommit to automate and refine commit messages.
-   **Project Hygiene:** Utilized tools to generate a `.gitignore` file, keeping my repository clean from unwanted files.

Today was about laying the groundwork for a seamless development process that incorporates both traditional practices and innovative AI tools. I’m excited to see how these tools will enhance my workflow as I move forward with the project.

---

### Day 3: Docker Configuration and Learning the CI/CD Workflow

Today's progress focused on setting up Docker for both the front-end and back-end components of my To-Do List application. Although I only created four files, the learning curve was steep and extremely rewarding.

**Key Configurations:**

-   **Dockerfiles:** I crafted separate Dockerfiles for the front-end and back-end folders. This process felt like assembling a new machine—each Dockerfile scripts the setup of a new environment, essentially virtualizing a clean slate where my code can run. This helps mitigate the notorious "it works on my machine" problem.
-   **Docker Compose:** At the root of the project, I added a Docker Compose file, which manages how Docker containers are built from the Dockerfiles and how they interact.
-   **Environment Variables:** I learned to use `.env` files to manage sensitive information securely. By adding these to the `.gitignore` file, I ensure that secret keys and passwords stay out of the version-controlled codebase.

**CI/CD Integration:**
The workflow I'm learning involves several steps:

1. Write and compile code locally within Docker to ensure consistency across environments.
2. Push the code to GitHub, triggering a CI/CD process that builds Docker images and pushes them to DockerHub.
3. Once the code is production-ready, I deploy it by creating a new container in Azure, pulling the latest Docker image from DockerHub.
4. The application then goes live, hosted seamlessly on Azure.

**What I Learned Today:**

1. **Dockerfile Structure:** I learned that each stage in a Dockerfile is distinct, necessitating the use of the `COPY` command to transfer artifacts from one stage to another.
2. **Docker Compose Updates:** The new Docker Compose v2 format has simplified some aspects, notably eliminating the need for a version statement at the start of the file.
3. **Security with `.env` Files:** These files are crucial for separating sensitive information from other project files, enhancing security.
4. **Full Workflow Clarity:** The day ended with a much clearer understanding of how Docker and Azure will interact in my CI/CD pipeline, giving me confidence in the robustness of my deployment strategy.

Today was about building the foundations of a reliable development environment and deployment workflow. Understanding Docker's role in development and deployment has been enlightening, and I'm excited to see how these configurations will support my project's growth.

---

### Day 4: Setting Up the CI/CD Pipeline

Today was a pivotal day in the development of my To-Do List application as I completed the setup of my CI/CD pipeline using GitHub Actions. I crafted three action files tailored for the frontend, backend, and Docker image pushing processes.

**Challenges and Solutions:**

-   **Handling .env Files:** Initially, I struggled with managing `.env` files since they contain sensitive information and shouldn't be public. I learned that within the CI/CD process, I could dynamically create `.env` files using environment variables stored securely in GitHub. This discovery allows me to use `.env` files both locally and in the CI/CD pipeline without exposing sensitive data.

-   **Optimization vs. Local Resources:** I noticed that the CI/CD process on GitHub Actions runs at a similar speed to my local setup. Given my machine's limitations, this observation led me to reconsider the necessity of a dedicated local CI/CD setup. For now, I’ve decided that leveraging GitHub Actions is sufficient and more resource-efficient.

-   **Docker Image Tagging:** Tagging and managing Docker images presented another challenge. Since a single Docker Hub repository cannot hold two images, I needed a strategy to differentiate them. I opted to use tagged naming conventions like `realyushi/todo-list:backend-latest` and `realyushi/todo-list:frontend-latest`. This approach maintains logical and organized repositories without the need for multiple Docker Hub accounts.

-   **Simplifying Local Builds:** While I considered using Jenkins for local CI/CD, I realized it wasn’t necessary at this stage. Instead, I wrote a simple Makefile to streamline testing processes, complementing the user-friendly nature of Docker Compose.

-   **Version Stability in CI/CD:** A key lesson was the importance of specifying exact versions for environments in the CI/CD process, rather than relying on 'latest' versions. Choosing stable, specific versions helps avoid unexpected issues when newer versions are released.

**What I Learned Today:**

1. **GitHub Actions:** Configured CI/CD pipelines for building and testing applications.
2. **Docker Hub Deployment:** Automated the deployment of Docker images to Docker Hub via CI/CD.
3. **Secure .env Management:** Implemented strategies for securely managing environment variables.
4. **CI/CD Stability:** Understood the importance of using specific versions to ensure the CI/CD process remains stable.

The day was filled with technical insights and significant advancements in setting up a robust deployment workflow. The knowledge gained from configuring GitHub Actions and managing Docker operations will undoubtedly enhance the efficiency and security of my development process.

---

### Days 5-7: Project Structure, Docker & CI/CD Enhancements, and BDD/TDD Introduction

The past three days have been a whirlwind of activity and learning as I dove deeper into setting up my To-Do List application. Embracing Test-Driven Development (TDD) and Behavior-Driven Development (BDD) has significantly shaped my approach, influencing everything from project structure to testing methodologies.

**Project and Docker Configuration:**

-   **Project Structure:** I initialized the project’s folder structure and made crucial adjustments to the Dockerfiles. Learning to use multi-stage builds in Docker has been particularly beneficial, helping save time and resources by optimizing the build process.
-   **Docker Compose Files:** I also refined how I manage different environments (development, test, production) by using multiple Docker Compose files. This separation enhances clarity and control over each deployment stage.

**CI/CD Improvements:**

-   **Handling Tests:** A key improvement in my CI/CD pipeline was learning how to manage tests that are in a 'pending' state without triggering unnecessary notifications. This adjustment helps maintain a clean and efficient workflow.

**Introduction to BDD and TDD:**

-   **Behavior-Driven Development (BDD):** I adopted BDD to align the development process more closely with user expectations and needs. This approach starts with defining behaviors from a user’s perspective, which helps in deeply understanding what the product should deliver. For the frontend, I chose Cucumber.js, and for the backend, SpecFlow.
-   **Test Development:** Although I have not yet designed the API and frontend, making it premature to write unit tests, I have started to outline feature files in BDD style. These are currently in a pending state but will soon be developed alongside the actual features.

**Tooling and Frameworks:**

-   **Vite:** I experimented with Vite to initialize the frontend project, finding it remarkably straightforward and efficient—a tool I highly recommend.

**What I Learned:**

1. **Project Initialization:** Tools like Vite make setting up new projects incredibly efficient.
2. **Docker Enhancements:** Utilized multi-stage builds in Dockerfiles and learned to manage different stages with multiple Docker Compose files.
3. **CI/CD Tactics:** Improved handling of pending tests in CI/CD pipelines to avoid unnecessary alerts.
4. **Testing Concepts:** Gained a better understanding of BDD and TDD. The user-centric approach of BDD, facilitated by tools like Cucumber and SpecFlow, makes the test specifications very accessible and user-friendly.

These three days have been foundational in shaping the project’s architecture and workflow. I’m excited to continue building on this robust framework as I move closer to developing the functional aspects of the application.

---

### Week 1 Summary: Building Foundations and Embracing New Methodologies

The first week of developing my full-stack To-Do list application has been both exhausting and exhilarating. Everything is on track, and I'm truly enjoying the 'learn by doing' approach. I've not only equipped my development environment with all the necessary tools but have also embraced an integrated workflow that combines traditional practices with innovative methodologies such as BDD (Behavior-Driven Development) and TDD (Test-Driven Development). This has fundamentally reshaped how I approach software development, emphasizing thorough planning, diligent testing, and maintaining a clean and efficient workflow.

As I transition into the next phase, I'm eager to begin implementing the actual functionalities of the To-Do list application, building on the strong foundation I've established.

Thankfully, we are in the age of AI, which has been immensely helpful. Whenever I face challenges, I turn to ChatGPT for quick guidance. I highly recommend using this tool to anyone learning something new, though it's important to double-check since some of the information can be outdated. With a successful and enlightening first week behind me, I feel confident and ready to tackle Week 2.
